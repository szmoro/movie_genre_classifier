{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcQ91-I00D4E"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import itertools\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.util import minibatch, compounding\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FuORUxueEdws"
   },
   "source": [
    "Constants used to parametrize notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kV9VrVES_3LL"
   },
   "outputs": [],
   "source": [
    "# Path to the movies_metadata.csv file\n",
    "MOVIES_METADATA_FILE_PATH = '/opt/movie_classifier/data/movies_metadata.csv'\n",
    "\n",
    "# Genres to be used as classes (only the ones with at least 5000 movies)\n",
    "GENRES_TO_INCLUDE = ['Action', 'Comedy', 'Drama', 'Romance', 'Thriller']\n",
    "\n",
    "# Directory for saving the output model\n",
    "OUTPUT_DIR = '/opt/movie_classifier/spacy_model'\n",
    "\n",
    "# Spacy pretrained model\n",
    "SPACY_MODEL = 'en_core_web_lg'\n",
    "\n",
    "# Training batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Early stopping patience\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwX3YvjESAb6"
   },
   "source": [
    "Setting random seeds to make results reproducible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ER1MJ3ulR9-b"
   },
   "outputs": [],
   "source": [
    "random.seed(18)\n",
    "np.random.seed(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PP8EMy9ZFd4"
   },
   "outputs": [],
   "source": [
    "if OUTPUT_DIR is not None:\n",
    "    OUTPUT_DIR = Path(OUTPUT_DIR)\n",
    "    if not OUTPUT_DIR.exists():\n",
    "        OUTPUT_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_f_g2YTS6A3"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bu3i88mCEWb7"
   },
   "source": [
    "Loading the movies_metadata.csv in a pandas dataframe and selecting the colums of interest for the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1592,
     "status": "ok",
     "timestamp": 1577021549111,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "MLG-uyly0JWN",
    "outputId": "467af8f4-b691-4219-f64a-603d92bd5606"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  ...                                             genres\n",
       "0                    Toy Story  ...  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...\n",
       "1                      Jumanji  ...  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...\n",
       "2             Grumpier Old Men  ...  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...\n",
       "3            Waiting to Exhale  ...  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...\n",
       "4  Father of the Bride Part II  ...                     [{'id': 35, 'name': 'Comedy'}]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(MOVIES_METADATA_FILE_PATH)\n",
    "training_df = training_df[['overview', 'genres']]\n",
    "training_df = training_df.dropna()\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hG3TZyenFav9"
   },
   "source": [
    "The genres field currently is currently valued with a complex structure containing multiple entries (list of dicts). We are going to simplify it by mapping it to a list of strings corresponding to the genres names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQTUa01v0Pb_"
   },
   "outputs": [],
   "source": [
    "training_df.genres = training_df.genres.map(lambda x: [genre['name'] for genre in ast.literal_eval(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qorv1cssJsxk"
   },
   "source": [
    "In order to obtain a more balanced dataset, we are going to only keep movies in the dataset if their genre appears in at least 5000 entries; these genres were previously extracted and listed in the **GENRES_TO_INCLUDE** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehtD5Bc0Ja0K"
   },
   "outputs": [],
   "source": [
    "training_df.genres = training_df.genres.map(lambda x: np.intersect1d(GENRES_TO_INCLUDE, x).tolist())\n",
    "training_df = training_df[training_df['genres'].astype(str) != '[]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSSalifuZ9oQ"
   },
   "source": [
    "Final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3329,
     "status": "ok",
     "timestamp": 1577021550991,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "2qxpDoWWZ_wF",
    "outputId": "1fade847-684b-4af0-ecb3-a58531478d91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heat</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>[Action, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  ...                     genres\n",
       "0                    Toy Story  ...                   [Comedy]\n",
       "2             Grumpier Old Men  ...          [Comedy, Romance]\n",
       "3            Waiting to Exhale  ...   [Comedy, Drama, Romance]\n",
       "4  Father of the Bride Part II  ...                   [Comedy]\n",
       "5                         Heat  ...  [Action, Drama, Thriller]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSyXpsbNS3Qx"
   },
   "source": [
    "Splitting the dataframe in training, validation and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3572,
     "status": "ok",
     "timestamp": 1577021551248,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "6RfpGSes0QzN",
    "outputId": "b6c62488-96e8-4dc2-dc16-d74cde38b14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 31868 examples (24940 training, 2772 validation, 6928 test)\n"
     ]
    }
   ],
   "source": [
    "texts = training_df['overview'].values\n",
    "labels = training_df['genres'].values\n",
    "\n",
    "train_texts, test_texts, train_cats, test_cats = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_texts, val_texts, train_cats, val_cats = train_test_split(train_texts, train_cats, test_size=0.1, random_state=42)\n",
    "\n",
    "train_cats = [{genre: genre in y for genre in GENRES_TO_INCLUDE} for y in train_cats]\n",
    "test_cats = [{genre: genre in y for genre in GENRES_TO_INCLUDE} for y in test_cats]\n",
    "val_cats = [{genre: genre in y for genre in GENRES_TO_INCLUDE} for y in val_cats]\n",
    "\n",
    "train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "print(f'Using {len(train_texts) + len(test_texts)} examples ({len(train_texts)} training, {len(val_texts)} validation, {len(test_texts)} test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epibRU1gS_5t"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definin an evaluation funciton. This function will be used to evaluate the model's performance at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTugSoJF0UPL"
   },
   "outputs": [],
   "source": [
    "def evaluate(nlp, texts, cats):\n",
    "    \"\"\"\n",
    "    This method evaluates the performance of the nlp model on the\n",
    "    test texts and cats passed as parameters.\n",
    "    It returns a dictionary containing the following keys:\n",
    "      - textcat_p: the model precision (tp / (tp + fp))\n",
    "      - textcat_r: the model recall (tp / (tp + fn))\n",
    "      - textcat_f: the model F1 score (2 * (precision * recall) / (precision + recall))\n",
    "      - textcat_a: the model accuracy ((tp + tn) / (tp + tn + fp + fn))\n",
    "    \"\"\"\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(nlp.pipe(texts)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score, \"textcat_a\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfdR-i7hZB2S"
   },
   "source": [
    "Initializing the Spacy nlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16817,
     "status": "ok",
     "timestamp": 1577021564505,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "Lzq_j95IVxAD",
    "outputId": "02f11a18-2e92-42b3-d228-553f84f1ef29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model en_core_web_lg\n"
     ]
    }
   ],
   "source": [
    "is_using_gpu = spacy.prefer_gpu()\n",
    "if is_using_gpu:\n",
    "    spacy.require_gpu()\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "nlp = spacy.load(SPACY_MODEL)\n",
    "print(f'Loaded model {SPACY_MODEL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LK1fh8OBZRdw"
   },
   "source": [
    "Adding the model a new TextCategorizer pipeline component to be trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYO1S8LJXbKL"
   },
   "outputs": [],
   "source": [
    "# add the text classifier to the pipeline\n",
    "textcat = nlp.create_pipe(\n",
    "    \"textcat\", config={\"exclusive_classes\": False, \"architecture\": \"simple_cnn\"}\n",
    ")\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "\n",
    "# add label to text classifier\n",
    "for label in GENRES_TO_INCLUDE:\n",
    "    textcat.add_label(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fijp9Wl_ZQ1I"
   },
   "source": [
    "Training loop with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315682,
     "status": "ok",
     "timestamp": 1577021863383,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "kIAZwdP90WIq",
    "outputId": "3df73d09-8e66-4746-8fa0-4c373e35ea76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/389 [00:00<00:40,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "EPOCH\tLOSS\tP\tR\tF\tA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:27<00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\t0.075\t0.723\t0.572\t0.639\t0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 2/389 [00:00<00:30, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to genre-classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 388/389 [00:25<00:00, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\t0.061\t0.730\t0.585\t0.649\t0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:33<00:00, 11.70it/s]\n",
      "  1%|          | 2/389 [00:00<00:26, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to genre-classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 388/389 [00:25<00:00, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\t0.053\t0.723\t0.610\t0.662\t0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:33<00:00, 11.66it/s]\n",
      "  1%|          | 2/389 [00:00<00:27, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to genre-classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:27<00:00, 14.34it/s]\n",
      "  1%|          | 2/389 [00:00<00:25, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3\t0.046\t0.704\t0.614\t0.656\t0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 388/389 [00:25<00:00, 14.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4\t0.038\t0.705\t0.627\t0.664\t0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:32<00:00, 11.91it/s]\n",
      "  1%|          | 2/389 [00:00<00:28, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to genre-classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:27<00:00, 14.37it/s]\n",
      "  1%|          | 2/389 [00:00<00:25, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5\t0.031\t0.693\t0.622\t0.655\t0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:27<00:00, 14.33it/s]\n",
      "  1%|          | 2/389 [00:00<00:24, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6\t0.026\t0.688\t0.618\t0.651\t0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:27<00:00, 14.39it/s]\n",
      "  1%|          | 2/389 [00:00<00:26, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7\t0.021\t0.680\t0.617\t0.647\t0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:26<00:00, 14.58it/s]\n",
      "  1%|          | 2/389 [00:00<00:23, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8\t0.018\t0.681\t0.617\t0.647\t0.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:27<00:00, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9\t0.016\t0.678\t0.615\t0.645\t0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    print('EPOCH\\tLOSS\\tP\\tR\\tF\\tA')\n",
    "    best_f1 = -1\n",
    "    epochs = 0\n",
    "    while True:\n",
    "        losses = {}\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=BATCH_SIZE)\n",
    "        with tqdm(total=len(train_data) // BATCH_SIZE) as pbar:\n",
    "            for i, batch in enumerate(batches):\n",
    "                if i < len(train_data) // BATCH_SIZE:\n",
    "                    texts, annotations = zip(*batch)\n",
    "                    nlp.update(texts, annotations, sgd=optimizer, losses=losses)\n",
    "                    pbar.update(1)\n",
    "            with nlp.use_params(optimizer.averages):\n",
    "                  scores = evaluate(nlp, val_texts, val_cats)\n",
    "            print(f'\\n{epochs}\\t{losses[\"textcat\"]:.3f}\\t{scores[\"textcat_p\"]:.3f}\\t{scores[\"textcat_r\"]:.3f}\\t{scores[\"textcat_f\"]:.3f}\\t{scores[\"textcat_a\"]:.3f}')\n",
    "            if scores[\"textcat_f\"] > best_f1:\n",
    "                best_acc = scores[\"textcat_f\"]\n",
    "                with nlp.use_params(optimizer.averages):\n",
    "                    nlp.to_disk(OUTPUT_DIR)\n",
    "                print(\"Saved model to\", OUTPUT_DIR)\n",
    "                bad_epochs = 0\n",
    "            else:\n",
    "                bad_epochs += 1\n",
    "            epochs += 1\n",
    "            if bad_epochs == PATIENCE:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciW3eYp52Z1N"
   },
   "source": [
    "# Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c1uVEunt2b-6"
   },
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 324859,
     "status": "ok",
     "timestamp": 1577021872568,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "xhSMmuZzoQ1X",
    "outputId": "eb916fee-3d69-43fd-de53-90453afce3ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./genre-classifier\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading from {OUTPUT_DIR}\")\n",
    "nlp = spacy.load(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2teDf7J2XmU"
   },
   "source": [
    "Evaluating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 327265,
     "status": "ok",
     "timestamp": 1577021874981,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "pGYWVBUGodkI",
    "outputId": "adac1cd0-42bf-45e6-b124-d5742b4cd942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.678\n",
      " Recall: 0.615\n",
      " F1 Score: 0.645\n",
      " Accuracy: 0.788\n"
     ]
    }
   ],
   "source": [
    "test_scores = evaluate(nlp, val_texts, val_cats)\n",
    "print(f'Precision: {scores[\"textcat_p\"]:.3f}\\n Recall: {scores[\"textcat_r\"]:.3f}\\n F1 Score: {scores[\"textcat_f\"]:.3f}\\n Accuracy: {scores[\"textcat_a\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5llU57G2hW4"
   },
   "source": [
    "Model usage and output examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1577022309884,
     "user": {
      "displayName": "Moreno Vendra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBy-3BHNbelS-DLnzmfz7odGlThUbDEWVCRKBtW8Q=s64",
      "userId": "17243337288923185995"
     },
     "user_tz": -60
    },
    "id": "eZIiZX5l0aQA",
    "outputId": "bff80f6a-799a-4d08-96e0-2315aab8c5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evil Iago pretends to be friend of Othello in order to manipulate him to serve his own end in the film version of this Shakespeare classic.\n",
      "{'Action': 0.012063146568834782, 'Comedy': 0.17406924068927765, 'Drama': 0.571480929851532, 'Romance': 0.008160477504134178, 'Thriller': 0.009414924308657646}\n"
     ]
    }
   ],
   "source": [
    "test_description = \"The evil Iago pretends to be friend of Othello in order to manipulate him to serve his own end in the film version of this Shakespeare classic.\"\n",
    "\n",
    "# test the saved model\n",
    "doc = nlp(test_description)\n",
    "print(test_description)\n",
    "print(doc.cats)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "challange.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
